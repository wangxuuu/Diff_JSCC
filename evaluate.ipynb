{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate PSNR, SSIM, and LPIPS on CIFAR10\n",
    "from models.script_util import create_reverse_process, create_sampler\n",
    "import argparse\n",
    "import yaml\n",
    "from models import dist_util, logger\n",
    "from models.image_datasets import load_data\n",
    "from models.resample import create_named_schedule_sampler\n",
    "from models.script_util import (\n",
    "    model_and_diffusion_defaults,\n",
    "    encoder_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    create_encoder,\n",
    "    select_config,\n",
    "    create_diffusion\n",
    ")\n",
    "from models.train_util import TrainLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_classes': 10, 'dataset': 'cifar10', 'data_dir': '../data/cifar_train', 'log_dir': './jscc_log', 'model_path': './jscc_log/model100000.pt', 'encoder_path': './log/encoder010000.pt', 'jscc_encoder_path': './jscc_log/encoder100000.pt', 'dropout': 0.3, 'lr': 0.0001, 'weight_decay': 0.0, 'lr_anneal_steps': 100000, 'batch_size': 64, 'microbatch': -1, 'ema_rate': 0.9999, 'log_interval': 10, 'save_interval': 50000, 'resume_checkpoint': '', 'use_fp16': False, 'fp16_scale_growth': '1e-3', 'image_size': 32, 'num_channels': 128, 'num_res_blocks': 3, 'num_heads': 4, 'num_heads_upsample': -1, 'attention_resolutions': '16,8', 'learn_sigma': True, 'diffusion_steps': 4000, 'noise_schedule': 'cosine', 'schedule_sampler': 'uniform', 'sigma_small': False, 'class_cond': True, 'timestep_respacing': '', 'use_kl': False, 'predict_xstart': False, 'rescale_timesteps': True, 'rescale_learned_sigmas': True, 'use_checkpoint': False, 'use_scale_shift_norm': True, 'num_samples': 100, 'clip_denoised': True, 'use_ddim': True, 'encoder_type': 'jscc', 'use_label_embed': False, 'use_time_embed': False, 'use_latent': True, 'latent_dim': 512, 'out_channels': 512, 'hidden_dims': [12, 24, 48, 96, 512]}\n"
     ]
    }
   ],
   "source": [
    "with open('configs/cifar10.yaml', 'r') as f:\n",
    "    try:\n",
    "        config = yaml.safe_load(f)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributed training\n",
    "dist_util.setup_dist()\n",
    "\n",
    "model, diffusion = create_model_and_diffusion(\n",
    "        **select_config(config, model_and_diffusion_defaults().keys())\n",
    "    )\n",
    "model.to(dist_util.dev())\n",
    "model.load_state_dict(\n",
    "        dist_util.load_state_dict(config['model_path'], map_location=\"cpu\")\n",
    "    )\n",
    "\n",
    "if config['encoder_type'] == 'unet':\n",
    "    encoder = create_encoder(**select_config(config, encoder_defaults().keys()))\n",
    "    encoder.to(dist_util.dev())\n",
    "    encoder.load_state_dict(\n",
    "        dist_util.load_state_dict(config['encoder_path'], map_location=\"cpu\")\n",
    "    )\n",
    "elif config['encoder_type'] == 'jscc':\n",
    "    from models.autoencoder import JSCC_encoder\n",
    "    encoder = JSCC_encoder(hidden_dims=config['hidden_dims'])\n",
    "    encoder.to(dist_util.dev())\n",
    "    encoder.load_state_dict(\n",
    "        dist_util.load_state_dict(config['jscc_encoder_path'], map_location=\"cpu\")\n",
    "    )\n",
    "\n",
    "schedule_sampler = create_named_schedule_sampler(config['schedule_sampler'], diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_data(\n",
    "    data_dir=config['data_dir'],\n",
    "    batch_size=config['batch_size'],\n",
    "    image_size=config['image_size'],\n",
    "    class_cond=config['class_cond'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_func = create_reverse_process(config, T=250)\n",
    "sample_fn = create_sampler(config, T=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from piq import FID, ssim, psnr, MSID, LPIPS\n",
    "metric_fid = FID()\n",
    "metric_ssim = ssim\n",
    "metric_psnr = psnr\n",
    "\n",
    "res_fid = 0\n",
    "res_ssim = 0\n",
    "res_psnr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, cond = next(data)\n",
    "batch = batch.to(dist_util.dev())\n",
    "cond['y'] = cond['y'].to(dist_util.dev())\n",
    "\n",
    "model_kwargs = {}\n",
    "model_kwargs[\"y\"] = cond['y']\n",
    "z = encoder(batch)\n",
    "model_kwargs[\"latent\"] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = reverse_func(model, batch, model_kwargs=model_kwargs)\n",
    "# generated samples\n",
    "sample = sample_fn(\n",
    "    model,\n",
    "    (config['batch_size'], 3, config['image_size'], config['image_size']),\n",
    "    noise=out['sample'],\n",
    "    clip_denoised=config['clip_denoised'],\n",
    "    model_kwargs=model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mlatent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m z\n\u001b[1;32m      9\u001b[0m \u001b[39m# final noising output\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m out \u001b[39m=\u001b[39m reverse_func(model, batch, model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs)\n\u001b[1;32m     11\u001b[0m \u001b[39m# generated samples\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sample \u001b[39m=\u001b[39m sample_fn(\n\u001b[1;32m     13\u001b[0m     model,\n\u001b[1;32m     14\u001b[0m     (config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m3\u001b[39m, config[\u001b[39m'\u001b[39m\u001b[39mimage_size\u001b[39m\u001b[39m'\u001b[39m], config[\u001b[39m'\u001b[39m\u001b[39mimage_size\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     model_kwargs\u001b[39m=\u001b[39mmodel_kwargs,\n\u001b[1;32m     18\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/wangxu/Diff_JSCC/models/gaussian_diffusion.py:582\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_reverse_sample_loop\u001b[0;34m(self, model, x, clip_denoised, denoised_fn, model_kwargs, eta, device)\u001b[0m\n\u001b[1;32m    580\u001b[0m t \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mtensor([i] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(sample), device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    581\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 582\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mddim_reverse_sample(model,\n\u001b[1;32m    583\u001b[0m                                    sample,\n\u001b[1;32m    584\u001b[0m                                    t\u001b[39m=\u001b[39;49mt,\n\u001b[1;32m    585\u001b[0m                                    clip_denoised\u001b[39m=\u001b[39;49mclip_denoised,\n\u001b[1;32m    586\u001b[0m                                    denoised_fn\u001b[39m=\u001b[39;49mdenoised_fn,\n\u001b[1;32m    587\u001b[0m                                    model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    588\u001b[0m                                    eta\u001b[39m=\u001b[39;49meta)\n\u001b[1;32m    589\u001b[0m     sample \u001b[39m=\u001b[39m out[\u001b[39m'\u001b[39m\u001b[39msample\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    590\u001b[0m     \u001b[39m# [1, ..., T]\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/wangxu/Diff_JSCC/models/gaussian_diffusion.py:538\u001b[0m, in \u001b[0;36mGaussianDiffusion.ddim_reverse_sample\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs, eta)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mSample x_{t+1} from the model using DDIM reverse ODE.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39massert\u001b[39;00m eta \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mReverse ODE only for deterministic path\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 538\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_mean_variance(\n\u001b[1;32m    539\u001b[0m     model,\n\u001b[1;32m    540\u001b[0m     x,\n\u001b[1;32m    541\u001b[0m     t,\n\u001b[1;32m    542\u001b[0m     clip_denoised\u001b[39m=\u001b[39;49mclip_denoised,\n\u001b[1;32m    543\u001b[0m     denoised_fn\u001b[39m=\u001b[39;49mdenoised_fn,\n\u001b[1;32m    544\u001b[0m     model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    545\u001b[0m )\n\u001b[1;32m    546\u001b[0m \u001b[39m# Usually our model outputs epsilon, but we re-derive it\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# in case we used x_start or x_prev prediction.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m eps \u001b[39m=\u001b[39m (\n\u001b[1;32m    549\u001b[0m     _extract_into_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqrt_recip_alphas_cumprod, t, x\u001b[39m.\u001b[39mshape) \u001b[39m*\u001b[39m x\n\u001b[1;32m    550\u001b[0m     \u001b[39m-\u001b[39m out[\u001b[39m\"\u001b[39m\u001b[39mpred_xstart\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    551\u001b[0m ) \u001b[39m/\u001b[39m _extract_into_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msqrt_recipm1_alphas_cumprod, t, x\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Documents/wangxu/Diff_JSCC/models/respace.py:91\u001b[0m, in \u001b[0;36mSpacedDiffusion.p_mean_variance\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mp_mean_variance\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     90\u001b[0m ):  \u001b[39m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mp_mean_variance(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_model(model), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/wangxu/Diff_JSCC/models/gaussian_diffusion.py:260\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m B, C \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    259\u001b[0m \u001b[39massert\u001b[39;00m t\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (B,)\n\u001b[0;32m--> 260\u001b[0m model_output \u001b[39m=\u001b[39m model(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scale_timesteps(t), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_var_type \u001b[39min\u001b[39;00m [ModelVarType\u001b[39m.\u001b[39mLEARNED, ModelVarType\u001b[39m.\u001b[39mLEARNED_RANGE]:\n\u001b[1;32m    263\u001b[0m     \u001b[39massert\u001b[39;00m model_output\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (B, C \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:])\n",
      "File \u001b[0;32m~/Documents/wangxu/Diff_JSCC/models/respace.py:122\u001b[0m, in \u001b[0;36m_WrappedModel.__call__\u001b[0;34m(self, x, ts, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrescale_timesteps:\n\u001b[1;32m    121\u001b[0m     new_ts \u001b[39m=\u001b[39m new_ts\u001b[39m.\u001b[39mfloat() \u001b[39m*\u001b[39m (\u001b[39m1000.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_num_steps)\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x, new_ts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/piq/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/wangxu/Diff_JSCC/models/unet.py:513\u001b[0m, in \u001b[0;36mUNetModel.forward\u001b[0;34m(self, x, timesteps, y, latent)\u001b[0m\n\u001b[1;32m    511\u001b[0m     h \u001b[39m=\u001b[39m module(cat_in, emb)\n\u001b[1;32m    512\u001b[0m h \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mtype(x\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 513\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout(h)\n",
      "File \u001b[0;32m~/anaconda3/envs/piq/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/piq/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/piq/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/wangxu/Diff_JSCC/models/nn.py:19\u001b[0m, in \u001b[0;36mGroupNorm32.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x\u001b[39m.\u001b[39;49mfloat())\u001b[39m.\u001b[39mtype(x\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/piq/lib/python3.10/site-packages/torch/nn/modules/normalization.py:273\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 273\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mgroup_norm(\n\u001b[1;32m    274\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_groups, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m~/anaconda3/envs/piq/lib/python3.10/site-packages/torch/nn/functional.py:2528\u001b[0m, in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2526\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(group_norm, (\u001b[39minput\u001b[39m, weight, bias,), \u001b[39minput\u001b[39m, num_groups, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps)\n\u001b[1;32m   2527\u001b[0m _verify_batch_size([\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m*\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_groups, num_groups] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m:]))\n\u001b[0;32m-> 2528\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mgroup_norm(\u001b[39minput\u001b[39;49m, num_groups, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_kwargs = {}\n",
    "for i, (batch, cond) in enumerate(data):\n",
    "    batch = batch.to(dist_util.dev())\n",
    "    cond['y'] = cond['y'].to(dist_util.dev())\n",
    "    \n",
    "    model_kwargs[\"y\"] = cond['y']\n",
    "    z = encoder(batch)\n",
    "    model_kwargs[\"latent\"] = z\n",
    "    # final noising output\n",
    "    out = reverse_func(model, batch, model_kwargs=model_kwargs)\n",
    "    # generated samples\n",
    "    sample = sample_fn(\n",
    "        model,\n",
    "        (config['batch_size'], 3, config['image_size'], config['image_size']),\n",
    "        noise=out['sample'],\n",
    "        clip_denoised=config['clip_denoised'],\n",
    "        model_kwargs=model_kwargs,\n",
    "    )\n",
    "    # calculate metrics\n",
    "    res_fid += metric_fid(sample.view(-1,config['image_size']**2), batch.view(-1,config['image_size']**2)).item()\n",
    "    res_ssim += metric_ssim((sample+1)/2, (batch+1)/2).item()\n",
    "    res_psnr += metric_psnr((sample+1)/2, (batch+1)/2).item()\n",
    "    if i % 10 == 0:\n",
    "        print(f'batch {i} done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ec660b0ea2d828e76e2eed44f0430f21c361a11018087dd77967b17f7ee22b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
