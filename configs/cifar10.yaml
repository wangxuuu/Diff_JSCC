## for cifar10

#============= save path =============#
num_classes: 10
dataset: "cifar10"
data_dir: "../data/cifar_train"
log_dir: "./jscc_log"
model_path: './jscc_log/model100000.pt'
encoder_path: './log/encoder010000.pt'
jscc_encoder_path: './jscc_log/encoder100000.pt'

#============= training parameters =============#
dropout: 0.3
lr: 0.0001
weight_decay: 0.0
lr_anneal_steps: 100000 # total training steps
batch_size: 64
microbatch: -1  # -1 disables microbatches
ema_rate: 0.9999  # comma-separated list of EMA values
log_interval: 10
save_interval: 50000 #10000
resume_checkpoint: ""
use_fp16: False
fp16_scale_growth: 1e-3

#============= model (Unet) setting =============#
image_size: 32
num_channels: 128
num_res_blocks: 3
num_heads: 4
num_heads_upsample: -1
attention_resolutions: "16,8"

#============= diffusion setting =============#
learn_sigma: True
diffusion_steps: 4000
noise_schedule: 'cosine'
schedule_sampler: "uniform"
sigma_small: False
class_cond: True
timestep_respacing: ""
use_kl: False
predict_xstart: False
rescale_timesteps: True
rescale_learned_sigmas: True
use_checkpoint: False
use_scale_shift_norm: True

#============= sampling setting =============#
num_samples: 100 # number of generated samples
clip_denoised: True
use_ddim: True

#============= Encoder =============#
encoder_type: 'jscc' # can set as 'jscc' 'unet'
use_label_embed: False # whether to condition on label when training the encoder
use_time_embed: False # set as False in default

use_latent: True # decide whether to conditioning on latent code of the data; used to create Unet
latent_dim: 512 # has to be same as out_channels if use latent diffusion; used to create Unet
out_channels: 512 # the dim of latent representation; used to create encoder
hidden_dims: [12, 24, 48, 96, 512] # only need when using JSCC encoder; the last dimension should keep as same as the latent dim above